{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "Loading[<u>¶</u>](https://www.kaggle.com/code/sillankumar/clean-vs-dirty-plate-img-data/notebook#Data-Loading)\n",
    "\n",
    "In \\[1\\]:\n",
    "\n",
    "*\\# This Python 3 environment comes with many helpful analytics\n",
    "libraries installed*\n",
    "\n",
    "*\\# It is defined by the kaggle/python Docker image:\n",
    "https://github.com/kaggle/docker-python*\n",
    "\n",
    "*\\# For example, here's several helpful packages to load*\n",
    "\n",
    "import numpy as np *\\# linear algebra*\n",
    "\n",
    "import pandas as pd *\\# data processing, CSV file I/O (e.g.\n",
    "pd.read_csv)*\n",
    "\n",
    "*\\# Input data files are available in the read-only \"../input/\"\n",
    "directory*\n",
    "\n",
    "*\\# For example, running this (by clicking run or pressing Shift+Enter)\n",
    "will list all files under the input directory*\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, \\_, filenames **in** os.walk('/kaggle/input'):\n",
    "\n",
    "for filename **in** filenames:\n",
    "\n",
    "print(os.path.join(dirname, filename))\n",
    "\n",
    "*\\# You can write up to 20GB to the current directory (/kaggle/working/)\n",
    "that gets preserved as output when you create a version using \"Save &\n",
    "Run All\"*\n",
    "\n",
    "*\\# You can also write temporary files to /kaggle/temp/, but they won't\n",
    "be saved outside of the current session*\n",
    "\n",
    "/kaggle/input/platesv2/sample_submission.csv\n",
    "\n",
    "/kaggle/input/platesv2/plates.zip\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "file='/kaggle/input/platesv2/plates.zip'\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "with ZipFile(file,'r') as zip:\n",
    "\n",
    "*#zip.printdir()*\n",
    "\n",
    "zip.extractall('/kaggle/working/')\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "print(os.listdir('/kaggle/working/'))\n",
    "\n",
    "data_root = '/kaggle/working/plates/'\n",
    "\n",
    "print(data_root)\n",
    "\n",
    "print(os.listdir(data_root))\n",
    "\n",
    "\\['\\_\\_MACOSX', '\\_\\_notebook\\_\\_.ipynb', 'plates'\\]\n",
    "\n",
    "/kaggle/working/plates/\n",
    "\n",
    "\\['.DS_Store', 'test', 'train'\\]\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "path_train = \"/kaggle/working/plates/train/\"\n",
    "\n",
    "path_test = \"/kaggle/working/plates/\"\n",
    "\n",
    "Image Augmentation\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import\n",
    "ImageDataGenerator,img_to_array,load_img\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "validation_split = 0.2\n",
    "\n",
    "train_datagen=ImageDataGenerator(validation_split=validation_split,rescale=1./255,rotation_range=45,shear_range=0.2,width_shift_range=0.2,height_shift_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\n",
    "\n",
    "validation_datagen=ImageDataGenerator(validation_split=validation_split\n",
    ",rescale=1./255)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(directory=path_train,classes=\\['cleaned','dirty'\\],batch_size=64,class_mode='binary',shuffle=True,target_size=(224,224),subset='training')\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(directory=path_train,classes=\\['cleaned','dirty'\\],batch_size=64,class_mode='binary',shuffle=True,target_size=(224,224),subset='validation')\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(directory=path_test,classes=\\['test'\\],batch_size\n",
    "= 1,shuffle = False,class_mode=None,target_size=(224,224))\n",
    "\n",
    "Found 32 images belonging to 2 classes.\n",
    "\n",
    "Found 8 images belonging to 2 classes.\n",
    "\n",
    "Found 744 images belonging to 1 classes.\n",
    "\n",
    "Model VGG16\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import\n",
    "Dense,InputLayer,BatchNormalization,Dropout,Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "basemodel=VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3))\n",
    "\n",
    "Downloading data from\n",
    "https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "**58889256/58889256** ━━━━━━━━━━━━━━━━━━━━ **0s** 0us/step\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "for layer **in** basemodel.layers:\n",
    "\n",
    "layer.trainable=False\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(basemodel)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu',\n",
    "kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=\\['accuracy'\\])\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "earlystopping=EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "patience=5, min_lr=1e-6)\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "history=model.fit(train_generator,epochs=100,validation_data=validation_generator,callbacks=\\[earlystopping,reduce_lr\\],verbose=1)\n",
    "\n",
    "Epoch 1/100\n",
    "\n",
    "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121:\n",
    "UserWarning: Your \\`PyDataset\\` class should call\n",
    "\\`super().\\_\\_init\\_\\_(\\*\\*kwargs)\\` in its constructor. \\`\\*\\*kwargs\\`\n",
    "can include \\`workers\\`, \\`use_multiprocessing\\`, \\`max_queue_size\\`. Do\n",
    "not pass these arguments to \\`fit()\\`, as they will be ignored.\n",
    "\n",
    "self.\\_warn_if_super_not_called()\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **16s** 16s/step - accuracy: 0.4688 - loss:\n",
    "10.8902 - val_accuracy: 0.5000 - val_loss: 9.7651 - learning_rate:\n",
    "0.0010\n",
    "\n",
    "Epoch 2/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6875 - loss:\n",
    "9.4149 - val_accuracy: 0.5000 - val_loss: 9.7890 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 3/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.5000 - loss:\n",
    "8.5989 - val_accuracy: 0.5000 - val_loss: 9.5840 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 4/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.5938 - loss:\n",
    "7.5469 - val_accuracy: 0.5000 - val_loss: 9.2695 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 5/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7500 - loss:\n",
    "6.6956 - val_accuracy: 0.5000 - val_loss: 8.6106 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 6/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7812 - loss:\n",
    "6.0688 - val_accuracy: 0.5000 - val_loss: 7.9346 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 7/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7188 - loss:\n",
    "5.4994 - val_accuracy: 0.5000 - val_loss: 7.2504 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 8/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "4.9430 - val_accuracy: 0.5000 - val_loss: 6.7382 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 9/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "4.4180 - val_accuracy: 0.5000 - val_loss: 6.2085 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 10/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6875 - loss:\n",
    "4.3306 - val_accuracy: 0.3750 - val_loss: 5.6031 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 11/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6562 - loss:\n",
    "4.0848 - val_accuracy: 0.3750 - val_loss: 5.1548 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 12/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6875 - loss:\n",
    "3.7628 - val_accuracy: 0.3750 - val_loss: 4.8280 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 13/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6562 - loss:\n",
    "3.6338 - val_accuracy: 0.3750 - val_loss: 4.5644 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 14/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "3.3728 - val_accuracy: 0.3750 - val_loss: 4.3259 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 15/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "3.2297 - val_accuracy: 0.3750 - val_loss: 4.1578 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 16/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.8438 - loss:\n",
    "3.1219 - val_accuracy: 0.3750 - val_loss: 4.0202 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 17/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "3.0321 - val_accuracy: 0.3750 - val_loss: 3.9291 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 18/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.9848 - val_accuracy: 0.3750 - val_loss: 3.7812 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 19/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.9240 - val_accuracy: 0.3750 - val_loss: 3.6545 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 20/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.6562 - loss:\n",
    "3.0307 - val_accuracy: 0.5000 - val_loss: 3.4949 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 21/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "2.8080 - val_accuracy: 0.6250 - val_loss: 3.3698 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 22/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7500 - loss:\n",
    "2.8243 - val_accuracy: 0.5000 - val_loss: 3.3060 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 23/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **13s** 13s/step - accuracy: 0.8438 - loss:\n",
    "2.6465 - val_accuracy: 0.5000 - val_loss: 3.2344 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 24/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "2.5514 - val_accuracy: 0.5000 - val_loss: 3.1685 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 25/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.5000 - val_accuracy: 0.5000 - val_loss: 3.1023 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 26/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.5978 - val_accuracy: 0.3750 - val_loss: 3.0464 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 27/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7812 - loss:\n",
    "2.4375 - val_accuracy: 0.3750 - val_loss: 2.9848 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 28/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "2.3054 - val_accuracy: 0.5000 - val_loss: 2.9184 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 29/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.3376 - val_accuracy: 0.5000 - val_loss: 2.8329 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 30/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "2.2301 - val_accuracy: 0.3750 - val_loss: 2.7473 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 31/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "2.0937 - val_accuracy: 0.3750 - val_loss: 2.6810 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 32/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.9812 - val_accuracy: 0.3750 - val_loss: 2.6214 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 33/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7812 - loss:\n",
    "2.1366 - val_accuracy: 0.3750 - val_loss: 2.5735 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 34/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.9317 - val_accuracy: 0.3750 - val_loss: 2.5224 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 35/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.8880 - val_accuracy: 0.3750 - val_loss: 2.4795 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 36/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "1.8237 - val_accuracy: 0.3750 - val_loss: 2.4342 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 37/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.8750 - loss:\n",
    "1.8598 - val_accuracy: 0.3750 - val_loss: 2.3755 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 38/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "1.7464 - val_accuracy: 0.3750 - val_loss: 2.3316 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 39/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.8125 - loss:\n",
    "1.7679 - val_accuracy: 0.3750 - val_loss: 2.2763 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 40/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.7252 - val_accuracy: 0.3750 - val_loss: 2.2113 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 41/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.7188 - loss:\n",
    "1.7284 - val_accuracy: 0.3750 - val_loss: 2.1568 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 42/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.5882 - val_accuracy: 0.3750 - val_loss: 2.1132 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 43/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9688 - loss:\n",
    "1.4736 - val_accuracy: 0.3750 - val_loss: 2.0740 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 44/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "1.5323 - val_accuracy: 0.3750 - val_loss: 2.0373 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 45/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.5492 - val_accuracy: 0.3750 - val_loss: 1.9996 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 46/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 1.0000 - loss:\n",
    "1.3777 - val_accuracy: 0.3750 - val_loss: 1.9673 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 47/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "1.3851 - val_accuracy: 0.3750 - val_loss: 1.9469 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 48/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.4196 - val_accuracy: 0.3750 - val_loss: 1.9497 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 49/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9375 - loss:\n",
    "1.3120 - val_accuracy: 0.5000 - val_loss: 1.9516 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 50/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.3602 - val_accuracy: 0.5000 - val_loss: 1.9420 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 51/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9062 - loss:\n",
    "1.2796 - val_accuracy: 0.5000 - val_loss: 1.9189 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 52/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.8125 - loss:\n",
    "1.3907 - val_accuracy: 0.3750 - val_loss: 1.9078 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 53/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9375 - loss:\n",
    "1.2314 - val_accuracy: 0.3750 - val_loss: 1.8876 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 54/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.2974 - val_accuracy: 0.3750 - val_loss: 1.8533 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 55/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.2971 - val_accuracy: 0.3750 - val_loss: 1.8168 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 56/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **13s** 13s/step - accuracy: 0.8125 - loss:\n",
    "1.2886 - val_accuracy: 0.3750 - val_loss: 1.7623 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 57/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9375 - loss:\n",
    "1.1362 - val_accuracy: 0.3750 - val_loss: 1.7361 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 58/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8125 - loss:\n",
    "1.2506 - val_accuracy: 0.3750 - val_loss: 1.7067 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 59/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8438 - loss:\n",
    "1.1959 - val_accuracy: 0.3750 - val_loss: 1.6791 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 60/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **20s** 20s/step - accuracy: 0.7500 - loss:\n",
    "1.3282 - val_accuracy: 0.3750 - val_loss: 1.6786 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 61/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **13s** 13s/step - accuracy: 0.8125 - loss:\n",
    "1.2185 - val_accuracy: 0.3750 - val_loss: 1.6778 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 62/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.8750 - loss:\n",
    "1.1372 - val_accuracy: 0.3750 - val_loss: 1.6777 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 63/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9375 - loss:\n",
    "1.1199 - val_accuracy: 0.3750 - val_loss: 1.6801 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 64/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9375 - loss:\n",
    "1.0894 - val_accuracy: 0.3750 - val_loss: 1.6833 - learning_rate: 0.0010\n",
    "\n",
    "Epoch 65/100\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **12s** 12s/step - accuracy: 0.9688 - loss:\n",
    "1.0512 - val_accuracy: 0.3750 - val_loss: 1.6814 - learning_rate: 0.0010\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "val_loss,val_acc=model.evaluate(validation_generator)\n",
    "\n",
    "print(f'validation\n",
    "loss:**{**val_loss**}\\n**validation_accuracy:**{**val_acc**}**')\n",
    "\n",
    "**1/1** ━━━━━━━━━━━━━━━━━━━━ **2s** 2s/step - accuracy: 0.3750 - loss:\n",
    "1.6777\n",
    "\n",
    "validation loss:1.6776763200759888\n",
    "\n",
    "validation_accuracy:0.375\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "history_df.loc\\[:, \\['loss', 'val_loss'\\]\\].plot();\n",
    "\n",
    "print(\"Minimum validation loss:\n",
    "**{}**\".format(history_df\\['val_loss'\\].min()))\n",
    "\n",
    "Minimum validation loss: 1.6776762008666992\n",
    "\n",
    "Prediction\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "In \\[20\\]:\n",
    "\n",
    "IMG_DIM = (224, 224)\n",
    "\n",
    "*\\# Read in all O and R test images file paths. Shuffle and select 50\n",
    "random test images.*\n",
    "\n",
    "test_files = glob.glob('/kaggle/working/plates/test/\\*.jpg') *\\# Adjust\n",
    "file extension as per your image format*\n",
    "\n",
    "test_files = shuffle(test_files)\\[:50\\] *\\# Shuffle and select 50 random\n",
    "images*\n",
    "\n",
    "*\\# Extract images and labels*\n",
    "\n",
    "test_imgs = \\[\\]\n",
    "\n",
    "test_labels = \\[\\]\n",
    "\n",
    "for img **in** test_files:\n",
    "\n",
    "*\\# Load and resize image*\n",
    "\n",
    "img_array =img_to_array(load_img(img, target_size=IMG_DIM))\n",
    "\n",
    "test_imgs.append(img_array)\n",
    "\n",
    "*\\# Convert lists to numpy arrays*\n",
    "\n",
    "test_imgs = np.array(test_imgs)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "*\\# Standardize*\n",
    "\n",
    "test_imgs_scaled = test_imgs.astype('float32') / 255.0\n",
    "\n",
    "*\\# Define functions for label conversion*\n",
    "\n",
    "def class2num(label):\n",
    "\n",
    "return 0 if label == 'cleaned' else 1\n",
    "\n",
    "def num2class(num):\n",
    "\n",
    "return 'cleaned' if num \\< 0.5 else 'dirty'\n",
    "\n",
    "*\\# Convert labels to numerical format for model training*\n",
    "\n",
    "test_labels_enc = np.array(\\[class2num(label) for label **in**\n",
    "test_labels\\])\n",
    "\n",
    "*\\# Predict using the model*\n",
    "\n",
    "predictions_model_history = model.predict(test_imgs_scaled, verbose=0)\n",
    "\n",
    "*\\# Convert predictions from probabilities to class labels*\n",
    "\n",
    "predictions_model_labels = np.array(\\[num2class(pred\\[0\\]) for pred\n",
    "**in** predictions_model_history\\])\n",
    "\n",
    "*\\# Example of predicting on a single custom image*\n",
    "\n",
    "custom_im = test_imgs_scaled\\[2\\] *\\# Assuming index 2 is a valid index\n",
    "in your test set*\n",
    "\n",
    "plt.imshow(custom_im)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "*\\# Reshape and predict with the model*\n",
    "\n",
    "custom_im = custom_im.reshape((1, IMG_DIM\\[0\\], IMG_DIM\\[1\\], 3)) *\\#\n",
    "Reshape to match model input shape*\n",
    "\n",
    "prediction_custom_im = model.predict(custom_im, verbose=0)\n",
    "\n",
    "*\\# If predictions are probabilities, use the following line*\n",
    "\n",
    "print(f\"Prediction for custom image:\n",
    "**{**num2class(prediction_custom_im\\[0\\]\\[0\\])**}**\")\n",
    "\n",
    "Prediction for custom image: dirty\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "preds = model.predict(test_generator, verbose=True)\n",
    "\n",
    "labels = \\['dirty' if x \\> 0.5 else 'cleaned' for x **in** preds\\]\n",
    "\n",
    "submission_df =\n",
    "pd.read_csv('/kaggle/input/platesv2/sample_submission.csv')\n",
    "\n",
    "submission_df\\['label'\\] = labels\n",
    "\n",
    "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121:\n",
    "UserWarning: Your \\`PyDataset\\` class should call\n",
    "\\`super().\\_\\_init\\_\\_(\\*\\*kwargs)\\` in its constructor. \\`\\*\\*kwargs\\`\n",
    "can include \\`workers\\`, \\`use_multiprocessing\\`, \\`max_queue_size\\`. Do\n",
    "not pass these arguments to \\`fit()\\`, as they will be ignored.\n",
    "\n",
    "self.\\_warn_if_super_not_called()\n",
    "\n",
    "**744/744** ━━━━━━━━━━━━━━━━━━━━ **212s** 285ms/step\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
